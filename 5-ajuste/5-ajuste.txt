AJUSTE DE CURVAS      En múltiples ocasiones se encuentran situaciones en las que se requiere analizar la relación entre dos variables cuantitativas. Los dos objetivos fundamentales de este análisis serán:* Determinar si dichas variables están asociadas y en qué sentido se da dicha asociación (es decir, si los valores de una de las variables tienden a aumentar –o disminuir- al aumentar los valores de la otra); * Estudiar si los valores de una variable pueden ser utilizados para predecir el valor de la otra.       La forma correcta de abordar el primer problema es recurriendo a coeficientes de correlación. Sin embargo, el estudio de la correlación es insuficiente para obtener una respuesta a la segunda cuestión: se limita a indicar la fuerza de la asociación mediante un único número, tratando las variables de modo simétrico, mientras que lo que interesa es modelizar dicha relación y usar una de las variables para explicar la otra.       Para tal propósito se recurrirá a la técnica de regresión. Aquí se analizará el caso más sencillo en el que se considera únicamente la relación entre dos variables (x e y). Así mismo, se limita al caso en el que la relación que se pretende modelizar es de tipo lineal. En este caso, la media de la distribución de las y sobre x está dada por ?????.x.      LA RECTA DE REGRESIÓN      Considérese una variable aleatoria respuesta (o dependiente) y, que se supone relacionada con otra variable (no necesariamente aleatoria) que se llamará explicativa, predictora o independiente y que se denotará por x.       A partir de una muestra de n individuos para los que se dispone de los valores de ambas variables, {(xi,yi),i = 1,...n}, se puede visualizar gráficamente la relación existente entre ambas mediante un gráfico de dispersión, en el que los valores de la variable x se disponen en el eje horizontal y los de y en el vertical. El problema que subyace a la metodología de la regresión lineal simple es el de encontrar una recta que ajuste a la nube de puntos del diagrama así dibujado, y que pueda ser utilizada para predecir los valores de y a partir de los de x. La ecuación general de la recta de regresión será entonces de la forma: ?????.x.      El problema radica en encontrar aquella recta que mejor ajuste a los datos. Tradicionalmente se ha recurrido para ello al método de mínimos cuadrados, que elige como recta de regresión a aquella que minimiza las distancias verticales de las observaciones a la recta.       Cualquier observación i-ésima yi diferirá verticalmente de esa recta (por ahora desconocida) en un valor ?i. Luego ? es el valor de una variable aleatoria.       	El valor de ? para cualquier observación determinada dependerá de un posible error de medición y de los valores de otras variables distintas de x que podrían influir sobre y.	Habrá que calcular los valores de   ??y  ? de la línea de regresión, es decir la ecuación de la recta que de alguna manera da el mejor ajuste. En referencia al gráfico anterior, es relativamente fácil trazarla a simple vista con un poco de sentido común. Sin embargo, lo habitual es recurrir a un método menos subjetivo.	Para plantear este problema de manera formal, considérese n parejas de observaciones (xi,yi) en las cuales es razonable suponer que la regresión de y sobre x es lineal, y se desea determinar la recta del mejor ajuste. Si se predice y por medio de la ecuación:      sea ei el error de predecir el valor de y correspondiente a la xi es:      	Se quiere determinar a y b de modo que estos errores sean, en cierto modo, lo más pequeños posibles. Ya que no se pueden minimizar cada uno de los ei por separado, esto sugiere intentar      tan cercano a cero como sea posible.	Esto no es aconsejable puesto que errores positivos y negativos se compensarán dando líneas inadecuadas como respuesta. Por lo tanto, se minimizará la suma de los cuadrados de ei. Es decir, se elegirán a y b de modo que:      	Esto equivale a minimizar la suma de los cuadrados de las distancias verticales a partir de los puntos respecto de la línea. Este método (llamado de los Mínimos Cuadrados) da valores de a y b (estimaciones de ? y ?) que tienen muchas propiedades convenientes.	Una condición necesaria para que exista un mínimo relativo es la anulación de las derivadas parciales con respecto a a y b:            lo que se puede reescribir como:            esto es un conjunto de ecuaciones lineales con incógnitas a y b, denominadas Ecuaciones Normales.	Resolviendo por determinantes:            Ejemplo: Los siguientes datos son las mediciones de la Tensión Arterial en 14 pacientes de distintas edades:ajustar una línea recta a estos datos por el método de mínimos cuadrados y utilizarla para estimar la tensión arterial para una persona de 36 años.	de aquí el sistema de ecuaciones queda:            	con la soluciones:      	Para una persona de 36 años de edad:	y = 0.79.(36)+109.7715 = 138.2122	En el siguiente gráfico se puede apreciar el Diagrama de Dispersión y la recta del mejor ajuste (desde el punto de vista de los mínimos cuadrados) y la estimación para una persona de 36 años de edad:	La siguiente función Matlab permite obtener los resultados vistos del proceso:      function recta      % Ajuste lineal de un conjunto de datos por Minimos Cuadrados      % con datos presentes en el archivo ascii regre.txt      % Entradas: u, vector, obtenido del archivo ascii "regre.txt"      % Salida: a, real, Ordenada al origen      %         b, real, pendiente de la recta	      load regre.txt;u=regre;n=size(u,1);      sy=0; for i=1:n, sy=sy+u(i,2);end      sx=0; for i=1:n, sx=sx+u(i,1);end      sx2=0; for i=1:n, sx2=sx2+u(i,1)^2;end      sxy=0; for i=1:n, sxy=sxy+u(i,1)*u(i,2);end      A(1,1)=n;A(1,2)=sx;A(2,1)=sx;A(2,2)=sx2;B(1,1)=sy;B(2,1)=sxy;      C=inv(A)*B;a=C(1,1);b=C(2,1);      i=1:n;plot(u(i,1),b*u(i,1)+a,u(i,1),u(i,2),'*')      a      b	El Teorema de Gauss-Markov establece: Entre los estimadores insesgados de ? y ? que son lineales en los yi, los estimadores de mínimos cuadrados tienen la varianza ,ás pequeña.INFERENCIAS BASADAS EN ESTIMADORES DE MÍNIMOS CUADRADOS	En lo que sigue se supondrá que la regresión es lineal y, más aún, que las n variables aleatorias que tienen valores yi (i=1, 2, …, n) son independientes y que están distribuidos normalmente con las medias ?????.xi y la varianza común ?2.	Si se escribe: yi = ?????.xi + ?i se deriva que los ?i son valores de variables aleatorias independientes, distribuidas normalmente, y que tienen medias 0 y varianza común ?2. Gráficamente:	En las suposiciones hechas hasta aquí, como se ilustra, se pueden advertir las distribuciones de los yi para varios valores de las xi.	Antes de establecer un teorema relativo a la distribución de los estimadores de mínimos cuadrados de ? y ?, es conveniente introducir una notación especial:                  en base a esto, las ecuaciones normales, resueltas por determinantes, quedan:      donde  e  son, respectivamente las medias de las x y de las y. Debe notarse también la estrecha relación entre las Sxx y Syy con las varianzas muestrales respectivas de las x y las y (sx y sy).      La varianza común ?2 puede estimarse en término de las desviaciones verticales de los puntos muestrales a partir de la línea de mínimos cuadrados. La i-ésima de tales desviaciones es:                   De aquí, la estimación, se2, es:      donde se se denomina Error Estándar de Estimación, también la suma de los cuadrados dada por se2.(n-2) recibe el nombre de Suma de Cuadrados Residual o Suma de Cuadrados de Error.	Una fórmula equivalente de esa estimación de ?2 es:        el divisor n-2 se emplea para que el estimador resultante de ?2 sea insesgado. 	En base a las suposiciones efectuadas relativas a la distribución de las y, se pueden probar los siguientes teoremas:Teorema 1: Con las suposiciones dadas, los estadísticos:      con valores de variables aleatorias que tienen la distribución t-Student con n-2 grados de libertad.	Si se requieren intervalos de confianza para los coeficientes de regresión ? y ?, se sustituye el término medio de –t??? < t < t??? por el estadístico t adecuado del teorema anterior. Luego, por medio de cálculos simples, se determinan los correspondientes intervalos de confianza:                  Problema: Los siguientes datos son las mediciones de la velocidad del aire y del coeficiente de evaporación de las gotitas de combustible en una turbina de propulsión:Velocidad del aire (cm/s)2060100140180220260300340380Coeficiente de Eva-poración (mm2/seg).18.37.35.78.56.751.181.361.171.65Construir un intervalo de confianza del 95% para el coeficiente de regresión ?.	                  	Gráficamente:	1-??= 0.05; ????= 0.025; t???? = 2.306  con ? = n – 2 = 8 g.d.l.los límites de confianza del 95%, para ?? se calculan entonces:            luego, el intervalo es:		      ??????????????????	En las pruebas de hipótesis relativas a los coeficientes de regresión ? y ?, las que se refieren a ? son muy importantes ya que ? es la pendiente de la línea de regresión. Esto es, ? es el “cambio promedio” de las y correspondiente a un incremento unitario de x. Si ??? la línea de regresión es horizontal y la media de las y no “depende linealmente” de x.Ejemplo: En base al problema anterior, probar la Hipótesis Nula de que ??? contra la Hipótesis Alterna que ????, con un nivel de significación de 0.05.   1. Hipótesis nula: ???   Hipótesis alterna: ????2. Nivel de significación 0.053. Criterio: Se rechaza Ho si t > 2.306 o t < -2.306, con ? = n – 2 = 8 g.d.l.4. Cálculos:    5. Decisión: Ya que 8.749 < 2.306  Se Rechaza la Hipótesis Nula. Luego, existe relación entre la velocidad del aire y el coeficiente de evaporación promedio (la relación es lineal por las suposiciones que fundamentan la prueba).   Otro problema es estimar ?????.x, es decir la media de la distribución de las y, para un valor dado de x. Si x se hace igual a un valor fijo x0 se desea estimar ?????.x0 y sería razonable emplear a???b.x0 (con a y b obtenidos por el método de los mínimos cuadrados). Puede verificarse que este estimador es insesgado, y que tiene la varianza:      y que los límites de confianza del (1-?).100% para ?????. x0 están dados por:      Problema: En relación al ejemplo anterior, construir un intervalo de confianza del 95% para el coeficiente de evaporación cuando la velocidad del aire es de 190 cm/seg.                          -0.681 < ?????. 190 < 0.913          intervalo de confianza	De mayor importancia aún que la estimación de ?????. x0 es la “predicción” de un valor futuro de y cuando x = x0 donde x0 está dentro del rango de experimentación (se agrega “dentro del rango de experimentación” dado que, la extrapolación es aventurada y se observa que una relación no siempre es válida fuera de tal rango). 	Para el primer problema se verifica que para una velocidad de 190 cm/seg (valor situado bien adentro del rango de experimentación) el coeficiente de evaporación es de 0.797 mm2/seg.	Se describirá un método para construir un intervalo en el cual puede esperarse que una futura observación y se halle con una probabilidad determinada (o confianza) cuando x = x0. Si se conocieran ??y ? se podría usar el hecho de que y es un valor de una variable aleatoria que tiene distribución normal con la media ?????. x0 y varianza ????o que y - ?????. x0 es un valor de una variable aleatoria con distribución normal de media cero y varianza ??).	Sin embargo ??y ? se desconocen, debiéndose considerar la cantidad y –a  - b.x0 (donde y, a, b son todas variables aleatorias y la teoría resultante origina los siguientes límites de predicción para y cuando x = x0.            Problema: Conforme al ejemplo anterior, encontrar los límites de predicción del 95% para una observación del coeficiente de evaporación cuando la velocidad del aire es de 190 cm/seg.      luego, los límites de predicción son:                  Comparando con el problema anterior, se ve que si bien la media de la distribución de las y cuando x=190 puede estimarse con bastante precisión, el valor de una simple estimación futura no puede predecirse con mucha precisión.	El ancho del intervalo de predicción depende fundamentalmente de se que mide la variabilidad inherente de los datos. Se nota que si se desea extrapolar, el intervalo de predicción (y también el intervalo de confianza para  ?????. x0) incrementa su ancho.Problema: Conforme al ejemplo anterior, suponer que la relación de linealidad se cumple más allá del rango de experimentación y calcular los límites de predicción del 95% para una observación del coeficiente de evaporación cuando la velocidad del aire es de 450 cm/seg.                  el ancho es de 2*0.46 = 0.92, contra los 2*0.385 = 0.77 del problema anterior.REGRESIÓN CURVILÍNEA	Se considerará primero el caso en que la graficación en una escala adecuada puede ser lineal. Por ejemplo, si un conjunto de parejas de datos que conste de n puntos (xi,yi) "se enderezan" cuando son graficados sobre ejes escalados adecuadamente. E este caso, al ser representados sobre papel semilogarítmico, indican que la curva de regresión de y sobre x es exponencial, es decir para cualquier x considerada, la media de la distribución está dada por la siguiente ecuación predictora y = ? . ? x, tomando logaritmos en ambos miembros:	y se puede estimar ahora log(?) y log(??, y de ahí obtener ? y ?, aplicando los métodos anteriores a los n pares de valores [xi,log(yi)].Problema: Las cifras siguientes son datos sobre el porcentaje de llantas radiales producidas por cierto fabricante que aún pueden usarse después de recorrer cierto número de millas:Miles de Millas recorridas (x)1251020304050Porcentaje útil (y)98.291.781.364.036.432.617.111.3Log(y)1.99211.96241.91011.80621.56111.51321.23301.0531a) Graficar los datos proporcionados en escala semilogaritmica para advertir si es razonable que la relación es exponencial.b) Ajustar una curva exponencial aplicando el método de mínimos cuadrados a las parejas de puntos [xi,log(yi)].c) Emplear los resultados de la parte b) para estimar qué porcentaje de las llantas radiales del fabricante durarán menos de 25000 millas.a)      El patrón global (del segundo gráfico) es lineal y esto justifica el ajuste mediante una curva exponencial.b) Para formar las ecuaciones normales:      ? x = 158   ? x2 = 5530  ? x.log(y) = 212.1224   ? y.log(y) = 13.0312      13.0312    = 8 log(a) + 158 log(b)      212.1224  = 158 log(a) + 5530 log(b)	log(a) = 1.9997  ==> a = 99.9408 	log(b) = -0.0188  ==> b = 0.9577      Luego, la ecuación de la recta de regresión estimada será:                   c) Utilizando la última expresión:      99.9408.(0.9577)25 = 33.9   Vale decir, el 33.9% durarán menos de 25000 millas.	La siguiente función de Matlab, produce los resultados vistos.      function logar(x)      % Regresion curvilinea de un conjunto de datos exponencial      % con datos presentes en el archivo ascii expo.txt      % Entradas: u, vector, obtenido del archivo ascii "expo.txt"      %           x, real, valor para el que se quiere hallar la estimacion       % Salida: a, real, Ordenada al origen del ajuste lineal      %         b, real, pendiente de la recta del ajuste linea      load expon.txt;u=expon';n=size(u,1);      slogy=0; for i=1:n, slogy=slogy+log10(u(i,2));end      sx=0; for i=1:n, sx=sx+u(i,1);end      sx2=0; for i=1:n, sx2=sx2+u(i,1)^2;end      slogxy=0; for i=1:n, slogxy=slogxy+u(i,1)*log10(u(i,2));end      A(1,1)=n;A(1,2)=sx;A(2,1)=sx;A(2,2)=sx2;B(1,1)=slogy;B(2,1)=slogxy;      C=inv(A)*B;a=C(1,1);b=C(2,1);      i=1:n;plot(u(i,1),b*u(i,1)+a,u(i,1),log10(u(i,2)),'*')      estima=(10^a)*(10^b)^xde modo que ejecutando:      >> logar(25)      estima =         33.9088	Hay dos relaciones más, muy aplicadas: La función potencial y = ? x? y la función recíproca y = 1/??????.x).      Para el primer caso, al ser representado el conjunto de datos sobre papel doble logarítmico toma la forma de recta, esto significa que los valores siguen una ley potencial.      Si la ecuación predictora está dada por:       y = ? . x ?   tomando logaritmos en ambos miembros, queda:            log(y) = log(?) + ? . log(x)      En este caso habrá que considerar tanto los logaritmos de los elementos de y como los de x.      Problema: Sea el siguiente conjunto de valores, las lecturas de un experimento donde x es la variable independiente (controlada, medida con poco error) e y la variable resultante.X1234567Y6.54090140250500700            ? log(x) = 3.7024   ? [log(x)]2 = 2.4890   ? log(x).log(y) = 8.8875         ? [log(y)] = 14.4574con lo que las ecuaciones normales quedan:      14.4574    = 7 log(a) + 3.7024 (b)      8.8875 = 3.7024 log(a) + 2.4890 (b)	log(a) = 0.8289  ==> a = 6.7437 	b = 2.338      Luego, la ecuación de la recta de regresión estimada será:      y’ = 0.8229 + ????? . x’y la función predictora:    y = 6.7437 . x2.338 	Los resultados gráficos son:	La siguiente función de Matlab, produce los resultados vistos.      function potencia(x)      % Regresion curvilinea de un conjunto de datos potencial      % con datos presentes en el archivo ascii poten.txt      % Entradas: u, vector, obtenido del archivo ascii "poten.txt"      %           x, real, valor para el que se quiere hallar la estimacion       % Salida: a, real, Ordenada al origen del ajuste lineal      %         b, real, pendiente de la recta del ajuste linea      %         estima, real, estimacion correspondiente a x      load poten.txt      load poten.txt;u=poten';n=size(u,1);      slogy=0; for i=1:n, slogy=slogy+log10(u(i,2));end      slogx=0; for i=1:n, slogx=slogx+log10(u(i,1));end      slogx2=0; for i=1:n, slogx2=slogx2+log10(u(i,1))^2;end      slogxy=0; for i=1:n, slogxy=slogxy+log10(u(i,1))*log10(u(i,2));end      A(1,1)=n;A(1,2)=slogx;A(2,1)=slogx;A(2,2)=slogx2;B(1,1)=slogy;B(2,1)=slogxy;      C=inv(A)*B;a=C(1,1);b=C(2,1);      a=10^a;      i=1:n;plot(u(i,1),a*u(i,1).^b,u(i,1),u(i,2),'*');      a      b      estima=a*x^bde modo que ejecutando:            >> potencia(2)      a =          6.7431      b =          2.3377      estima =         34.0872Para el caso de la función recíproca y = 1/??????.x), se obtienen ? y ?, aplicando los métodos anteriores a los n pares de valores [xi,1/ yi].Problema: Sea el siguiente conjunto de valores, las lecturas de un experimento donde x es la variable independiente (controlada, medida con poco error) e y la variable resultante.X1234567Y1.510.80.850.60.50.55      ? (x) = 28   ? x2 = 140  ? x.1/y = 44.183   ? 1/y = 9.578con lo que las ecuaciones normales quedan:            9.578    = 7 a + 28 b      44.183 = 28 a + 140 b       ==> a = 0.53 	b = 0.21            Luego, la ecuación de la recta de regresión estimada será:      y’ = 0.53 + ???? x’y la función predictora:    y = 1/(0.53 + 0.21 x) 	Los resultados gráficos son:	La siguiente función de Matlab, produce los resultados vistos.      function reciproca(x)      % Regresion curvilinea de un conjunto de datos reciprocos      % con datos presentes en el archivo ascii reci.txt      % Entradas: u, vector, obtenido del archivo ascii "reci.txt"      %           x, real, valor para el que se quiere hallar la estimacion       % Salida: a, real, Ordenada al origen del ajuste lineal      %         b, real, pendiente de la recta del ajuste linea      %         estima, real, estimacion correspondiente a x      load reci.txt;u=reci';n=size(u,1);      sy=0; for i=1:n, sy=sy+1/(u(i,2));end      sx=0; for i=1:n, sx=sx+u(i,1);end      sx2=0; for i=1:n, sx2=sx2+u(i,1)^2;end      sxy=0; for i=1:n, sxy=sxy+u(i,1)*1/u(i,2);end      A(1,1)=n;A(1,2)=sx;A(2,1)=sx;A(2,2)=sx2;B(1,1)=sy;B(2,1)=sxy;      C=inv(A)*B;a=C(1,1);b=C(2,1);      i=1:n;plot(u(i,1),1./(a+b*u(i,1)),u(i,1),u(i,2),'*');end      a      b      estima=1/(a+b*x)de modo que ejecutando:      >> reciproca(1)      a =          0.5295	b =          0.2097      estima =          1.3528	Si no hay ninguna indicación acerca de la forma funcional de la regresión de y sobre x, se supone a menudo que la relación fundamental al menos “se comporta bien” al grado que admita un desarrollo en Serie de Taylor y que los primeros términos constituyen una aproximación bastante buena.	Vale decir, los datos se ajustan a un polinomio o ecuación predictora de la forma 	y = ?0 +??1.x+??2.x2 +… +??p.xp      donde el grado se determina por observación de los datos o por un método más riguroso como el siguiente: dado un conjunto de datos que consta de n puntos (xi,yi) se estiman los coeficientes ?0 ,??1 ,??2,… ?p del polinomio de p-ésimo grado, minimizando:      diferenciado parcialmente con respecto a ?0 ,??1 ,??2,… ?p , igualando estas derivadas parciales a cero, reacomodando términos e indicando con bi las estimaciones de ?i, se obtienen las p+1ecuaciones normales:            	………………………………………………………………….      siendo b0, b1, …, bp las p+1 incógnitas.Problema: Los datos siguientes corresponden al tiempo de secado de cierto barniz y a la cantidad de un aditivo con que se intenta reducir el tiempo de secado:Cantidad de aditivo (en gr.)012345678Tiempo de secado (en seg.)12.010.510.08.07.08.07.58.59.0a) Dibujar el diagrama de dispersión de modo que permita advertir si es razonable una relación parabólica.b) Ajustar un polinomio de segundo grado por el método de mínimos cuadrados.c) Emplear el resultado de b) para predecir el valor del tiempo de secado cuando se han utilizado 6.5 gr. del aditivo.a)b) Cálculos:	 			      	      		            con lo que las ecuaciones normales quedan:            	b0 = 12.2	b1 = -1.85	b2 = 0.183 	La ecuación del polinomio será:      gráficamente:d) sustituyendo x = 6.5, da:          La siguiente función de Matlab, produce los resultados vistos.      function parabola(x)      % Regresion curvilinea de un conjunto de datos de origen cuadratico      % con datos presentes en el archivo ascii parabo.txt      % Entradas: u, vector, obtenido del archivo ascii "parabo.txt"      %           x, real, valor para el que se quiere hallar la estimacion       % Salida: b0, b1, b2, reale, coeficientes del polinomio de ajuste      %         estima, real, estimacion correspondiente a x      load parabo.txt;u=parabo';n=size(u,1);      sy=0; for i=1:n, sy=sy+u(i,2);end      sx=0; for i=1:n, sx=sx+u(i,1);end      sxy=0; for i=1:n, sxy=sxy+u(i,1)*u(i,2);end      sx2=0; for i=1:n, sx2=sx2+u(i,1)^2;end      sx3=0; for i=1:n, sx3=sx3+u(i,1)^3;end      sx4=0; for i=1:n, sx4=sx4+u(i,1)^4;end      sx2y=0; for i=1:n, sx2y=sx2y+(u(i,1)^2)*u(i,2);end      sy2=0; for i=1:n, sy2=sy2+u(i,2)^2;end      A(1,1)=n;A(1,2)=sx;A(1,3)=sx2;      A(2,1)=sx;A(2,2)=sx2;A(2,3)=sx3;      A(3,1)=sx2;A(3,2)=sx3;A(3,3)=sx4;      B(1,1)=sy;B(2,1)=sxy;B(3,1)=sx2y;      C=inv(A)*B;b0=C(1,1);b1=C(2,1);b2=C(3,1);      C      i=1:n;plot(u(i,1),b0+b1.*u(i,1)+b2.*u(i,1).^2,u(i,1),u(i,2),'*');end      estima=b0+b1*x+b2*x^2	de modo que ejecutando:      >> parabola(6.5)      C =         12.1848         -1.8465          0.1829      estima =	    7.9099	En la práctica, puede ser difícil determinar el grado del polinomio que se ajusta a un conjunto de parejas de datos. Como siempre, es posible hallar un polinomio de grado n-1 que pase a través de los n puntos correspondientes a n valores distintos de x. Debe ser claro el objetivo de encontrar un polinomio de grado mínimo que “describa adecuadamente” a los datos. A menudo es posible determinar el grado con la simple observación de los datos.	Existe también un método más estricto para determinar el grado de un polinomio que se ajuste a un conjunto de datos. En esencia, consiste en ajustar inicialmente a una línea recta, así como a un polinomio de segundo grado y probar la Hipótesis Nula ??=0. Es decir, nada se gana incluyendo el término cuadrático. 	Si esta Hipótesis Nula puede rechazarse, entonces se ajusta con un polinomio de tercer grado y se prueba la Ho ??=0. Es Es decir, nada se gana incluyendo el término cúbico.	Este procedimiento se continua hasta que la Ho ??=0 no pueda ser rechazada en dos etapas sucesivas, no existe pues ventaja en utilizar términos adicionales. Para aplicar estas pruebas, se requieren las suposiciones de normalidad, independencia y varianzas iguales introducidas al principio.AJUSTE POLINOMIAL MEDIANTE LA VARIAZA RESIDUAL		Como se ha dicho más arriba, cuando se ajusta un polinomio a un conjunto de parejas de datos, se suele empezar  ajustando una línea recta y se prueba la Ho ??=0. Entonces se ajusta un polinomio de segundo grado y se prueba si vale la pena conservar el término cuadrático comparando , la varianza residual después de ajustar la línea recta, con, la varianza residual después de ajustar el polinomio de segundo grado.	Cada una de estas varianzas residuales está dada por:      con  determinada, respectivamente, de la ecuación de la recta y de la ecuación de segundo grado. Los grados de libertad se determinan restando el número de puntos considerados y los coeficientes estimados.	Este proceso se reitera, hacia grados superiores, hasta que la varianza residual produzca “el salto decreciente más significativo”.Problema: Dado el siguiente conjunto de datos:x.51.52.55.56.59.510.512.514.515.5y3712.514.51614.516162123encontrar el polinomio de mejor ajuste.	Se intenta en primer lugar, el ajuste lineal. Para ello se determinan y resuelven  las ecuaciones normales:      ? x = 79   ? x2 = 888.5  ? x.y = 1394   ? y = 143.5            143.5 = 10 b0 + 79 b1   	1394 = 79 b0 + 888.5 b1           ==> b0 = 6.578        b1 = 0.984luego, se calcula la varianza residual:            Se sigue con un ajuste cuadrático:      ? x2 y = 16720   ? x3 = 11200    ? x4 = 149400            143.5 = 10 b0 + 79 b1 + 888.5 b2  	1394 = 79 b0 + 888.5 b1 + 11200 b2	16720 = 888.5 b0 + 11200 b1 + 149400 b2     ==> b0 = 5.399  b1 = 1.5  b1 = -0.033      y así hasta llegar a un polinomio de grado 9, que pasará por todos los puntos (varianza residual nula).	Una tabla con las varianzas residuales para cada ajuste es la siguiente (hasta el orden cuártico):LinealCuadráticoCúbicoCuartico7.2077.581.0210.992      Se ve que el salto mayor se produce entre el ajuste cuadrático y el cúbico, por lo tanto el mejor estimador lo constituye el ajuste cúbico.	Gráficamente:	La siguiente función de Matlab, permite encontrar las varianzas residuales para ajuste lineal y de mayor orden, lo que permite decidir el ajuste más conveniente a realizar:      function residual      % Ajuste de un conjunto de datos por medio de un polinomio      % con datos presentes en el archivo ascii resi.txt      % por el metodo de la varianza residual      % Entradas: u, vector, obtenido del archivo ascii "resi.txt"      % Salida: re, real, varianza residual para cada ajuste (desde lineal)      load resi.txt;u=resi';n=size(u,1);      A(1,1)=n;      B(1,1)=0; for i=1:n, B(1,1)=B(1,1)+u(i,2);end      B(2,1)=0; for i=1:n, B(2,1)=B(2,1)+u(i,2)*u(i,1);end      A(1,2)=0; for i=1:n, A(1,2)=A(1,2)+u(i,1);end      A(2,1)=A(1,2);      A(2,2)=0; for i=1:n, A(2,2)=A(2,2)+u(i,1)^2;end      C=inv(A)*B;re=0; for i=1:n, re=re+(u(i,2)-C(1,1)-C(2,1)*u(i,1))^2/(n-2);end      z=3;      re      while z<7,         for j=1:z              A(j,z)=0; for i=1:n, A(j,z)=A(j,z)+u(i,1)^(z+j-2);end             if j<z, A(z,j)=A(z-1,j+1);end         end         B(z,1)=0; for i=1:n, B(z,1)=B(z,1)+u(i,2)*u(i,1)^(z-1);end          C=inv(A)*B;         re=0;          for i=1:n,               aju=0;                  for j=1:z,                     aju=aju+(C(j,1)*u(i,1)^(j-1));                 end                 dif(i)=aju;                 re=re+(u(i,2)-dif(i))^2;             end             re=re/(n-z); z=z+1;             re         end	Ejecutando:      >> residual      re =          7.2069	re =          7.5798      re =          1.0206      re =          0.9917      re =          1.2390REGRESIÓN MÚLTIPLE	Es necesario señalar que las curvas obtenidas (y las superficies a obtener) no sólo se utilizan para hacer predicciones . A menudo también se emplean para fines de optimización, es decir, para determinar los valores de la variable independiente (o variables) de tal manera que la variable dependiente sea un máximo o un mínimo. En el caso del barniz del problema de ajuste cuadrático, el tiempo de secado tiene un mínimo cuando la cantidad de aditivo es de 5.1 gramos.      Esto se obtiene derivando   e igualando a cero.      Los métodos estadísticos de predicción y optimización suelen ser incluidos bajo el título general de Análisis de las Superficies de Respuesta.	En la regresión múltiple, se manejan datos que constan de n (r+1) coordenadas (x1i, x2i , …, xri, yi) donde otra vez se supone que las xi se conocen sin error,  mientras que las y son valores de variables aleatorias. Datos de esta clase aparecen en:* Estudios diseñados para determinar el efecto que ejercen en la resistencia mecánica de un metal la corrosión bajo varias condiciones climáticas.* El efecto que la temperatura de horneado, humedad  y contenido de hierro tienen en la resistencia mecánica de un revestimiento cerámico.* El efecto de la producción industrial, nivel de consumo y existencias almacenadas producen en el precio de un producto.   Como en el caso de una sola variable, en primer término se aborda el problema en que la ecuación de regresión es lineal, es decir cuando para cualquier conjunto determinado de valores x1, x2 , …, xr la media de la distribución es:   ?0 + ?1 x1 + ?2 x2 + …. + ?r xr        	En el caso de dos variables independientes, el problema es ajustar un plano a un conjunto de n puntos con coordenadas (x1i, x2i , yi). Gráficamente:	Aplicando el método de los mínimos cuadrados para obtener estimaciones de ?0, ?1 y ?2, se minimiza la suma de los cuadrados de las distancias verticales de los puntos del plano, es decir minimizar:      Las ecuaciones normales resultantes de la aplicación de derivadas parciales son:                  	Estas son las ecuaciones normales para regresión múltiple con r=2. Donde b0, b1 y b2 son estimadores de mínimos cuadrados para ?0, ?1 y ?2.Problema: Los datos siguientes provienen del número de torsiones necesarios para romper una barra hecha con cierto tipo de aleación y los porcentajes de metales que la integran:Nro, de Torsiones (x)38408559406068533135425918342942Porc. Del elemento A (x1)1234123412341234Porc. Del elemento B (x2)5555101010101515151520202020Ajustar un plano de regresión por mínimos cuadrados y emplear su ecuación para estimar el número de torsiones requeridas para romper una de las barras cuando x1= 2.5 y x2 = 12.	Sustituyendo en las ecuaciones normales anteriores:      ? x1 = 40   ? x2 = 200  ? x12= 120   ? x1 x2= 500  ? x22= 3000      ? y= 733   ? x1 y = 1989   ? x2 y = 8285            733 = 16 b0 + 40 b1 + 200 b2  	1989 = 40 b0 + 200 b1 + 500 b2	8285 = 200 b0 + 500 b1 + 3000 b2     ==> b0 = 48.2  b1 = 7.83  b1 = -1.76      el plano de regresión tiene entonces la ecuación:      sustituyendo por x1= 2.5 y x2 = 12:      	La siguiente función de Matlab, permite encontrar los coeficientes del plano de regresión y la estimación para una par de valores x1 y x2.      function multiple(x1,x2)      % Regresion multiple de un conjunto de datos       % con datos presentes en el archivo ascii multip.txt      % Entradas: u, matriz, obtenida del archivo ascii "multip.txt"      %           x1,x2, reales, valores para los que se quiere hallar la estimacion       % Salida: b0, b1, b2, reales, coeficientes del polinomio de ajuste      %         estima, real, estimacion correspondiente a x      load multip.txt;u=multip';n=size(u,1);      sy=0; for i=1:n, sy=sy+u(i,1);end      sx1=0; for i=1:n, sx1=sx1+u(i,2);end      sx2=0; for i=1:n, sx2=sx2+u(i,3);end      sx12=0; for i=1:n, sx12=sx12+u(i,2)^2;end      sx22=0; for i=1:n, sx22=sx22+u(i,3)^2;end      sx1x2=0; for i=1:n, sx1x2=sx1x2+u(i,2)*u(i,3);end      sx1y=0; for i=1:n, sx1y=sx1y+u(i,2)*u(i,1);end      sx2y=0; for i=1:n, sx2y=sx2y+u(i,3)*u(i,1);end      A(1,1)=n;A(1,2)=sx1;A(1,3)=sx2;      A(2,1)=sx1;A(2,2)=sx12;A(2,3)=sx1x2;      A(3,1)=sx2;A(3,2)=sx1x2;A(3,3)=sx22;      B(1,1)=sy;B(2,1)=sx1y;B(3,1)=sx2y;      C=inv(A)*B;b0=C(1,1);b1=C(2,1);b2=C(3,1);      estima=b0+b1*x1+b2*x2	Ejecutando:      >> multiple(2.5,12)      C =         48.1875          7.8250         -1.7550      estima =         46.6900Universidad de Mendoza                                                                                    Ing. Jesús Rubén Azor Montoya120______________________________________________________________________Cátedra Estadística Aplicada II